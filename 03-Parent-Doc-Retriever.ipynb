{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/Retriever/blob/main/03-Parent-Doc-Retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNzSQ3VZffUe"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IktJaHr9fwj_"
      },
      "outputs": [],
      "source": [
        "!echo \"OPENAI_API_KEY=\" >> .env\n",
        "!source /content/.env\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsRwJ2Bpgt7N"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDpddet9rEJC",
        "outputId": "8320ccd5-1014-4ce2-cd99-e92d1688c3d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(temperature=0, model='gpt-4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z32iJnXrNvn",
        "outputId": "f4bb5570-1ace-416a-9b6d-9470bba7a93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 1 document with length 24854 characters or roughly 6213.5 tokens\n"
          ]
        }
      ],
      "source": [
        "# Loading a single website\n",
        "loader = WebBaseLoader(\"http://www.paulgraham.com/superlinear.html\")\n",
        "paul_graham_essay = loader.load()\n",
        "print (f\"You have {len(paul_graham_essay)} document with length {len(paul_graham_essay[0].page_content)} characters or roughly {len(paul_graham_essay[0].page_content) / 4} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wrNQtEEOraEb"
      },
      "outputs": [],
      "source": [
        "# Split your website into big chunks\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000 * 4, chunk_overlap=0)\n",
        "\n",
        "# This text splitter is used to create the child documents. They should be small chunk size.\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=125*4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqCb_KA8reHG",
        "outputId": "012315b0-a280-4b6f-93a8-dc14384f156a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"parent_document_splits\",\n",
        "    embedding_function=OpenAIEmbeddings()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2udDz5FYrqQZ"
      },
      "outputs": [],
      "source": [
        "# The storage layer for the parent documents\n",
        "docstore = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "A3MkCsWUrreh"
      },
      "outputs": [],
      "source": [
        "retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x_YxEDeqrvDO"
      },
      "outputs": [],
      "source": [
        "retriever.add_documents(paul_graham_essay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0qzUXXcsIqv",
        "outputId": "56ca39eb-c002-4793-e337-aaebedb38bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 16 parent docs and 82 child docs\n"
          ]
        }
      ],
      "source": [
        "num_parent_docs = len(retriever.docstore.store.items())\n",
        "num_child_docs = len(set(retriever.vectorstore.get()['documents']))\n",
        "\n",
        "print (f\"You have {num_parent_docs} parent docs and {num_child_docs} child docs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT-ikGOXsTCE",
        "outputId": "41037004-1e08-4380-c384-fa3f9ccf3c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 child docs were found\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"as true in investing, for example. It's only useful to believe that\\na company will do well if most other investors don't; if everyone\\nelse thinks the company will do well, then its stock price will\\nalready reflect that, and there's no room to make money.What else can we learn from these fields? In all of them you have\\nto put in the initial effort. Superlinear returns seem small at\\nfirst. At this rate, you find yourself thinking, I'll never get\", metadata={'doc_id': 'c17e0905-dea3-46da-8935-6b3a65e9d330', 'language': 'No language found.', 'source': 'http://www.paulgraham.com/superlinear.html', 'title': 'Superlinear Returns'})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "child_docs = retriever.vectorstore.similarity_search(\"what is some investing advice?\")\n",
        "\n",
        "print (f\"{len(child_docs)} child docs were found\")\n",
        "child_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "YHN7a_8Ksei_",
        "outputId": "76003372-28bd-49bc-f0b6-9adbd48503bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"science. It has exponential growth, in the form of learning, combined\\nwith thresholds at the extreme edge of performance â€” literally at\\nthe limits of knowledge.The result has been a level of inequality in scientific discovery\\nthat makes the wealth inequality of even the most stratified societies\\nseem mild by comparison. Newton's discoveries were arguably greater\\nthan all his contemporaries' combined.\\n[11]This point may seem obvious, but it might be just as well to spell\\nit out. Superlinear retur\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.docstore.store.get(child_docs[0].metadata['doc_id']).page_content[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUzLAgwJsqZ-",
        "outputId": "b9c4a113-483b-4f4b-c7ba-b2d0f911356b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 retrieved docs were found\n"
          ]
        }
      ],
      "source": [
        "retrieved_docs = retriever.get_relevant_documents(\"what is some investing advice?\")\n",
        "\n",
        "print (f\"{len(retrieved_docs)} retrieved docs were found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QDqfed-s6qo"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "question = \"what is some investing advice?\"\n",
        "\n",
        "chat.predict(text=PROMPT.format_prompt(\n",
        "    context=retrieved_docs,\n",
        "    question=question\n",
        ").text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPZaxR1DZU4j8GsJ6ZT/qlt",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
